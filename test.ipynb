{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(ticker, start_date, end_date):\n",
    "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_average(data, window):\n",
    "    return data['Close'].rolling(window=window).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rsi(data, window=14):\n",
    "    delta = data['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_exit_signal(index_data, long_term_ma):\n",
    "    index_data['Long_Term_MA'] = index_data['Close'].rolling(window=long_term_ma).mean()\n",
    "    if index_data['Close'].iloc[-1] < index_data['Long_Term_MA'].iloc[-1]:\n",
    "        return \"Exit Market\"\n",
    "    return \"Stay\"\n",
    "def check_buy_signal(stock_data, short_window=5, long_window=20, rsi_buy_signal=40):\n",
    "    stock_data['Short_MA'] = calculate_moving_average(stock_data, short_window)\n",
    "    stock_data['Long_MA'] = calculate_moving_average(stock_data, long_window)\n",
    "    stock_data['RSI'] = calculate_rsi(stock_data)\n",
    "    stock_data['Volume_MA'] = stock_data['Volume'].rolling(window=short_window).mean()\n",
    "\n",
    "    # Check the latest data point for buy signal\n",
    "    buy_signal = (stock_data['Short_MA'].iloc[-1] < stock_data['Long_MA'].iloc[-1]) and \\\n",
    "                 (stock_data['RSI'].iloc[-1] < rsi_buy_signal) and \\\n",
    "                 (stock_data['Volume'].iloc[-1] > stock_data['Volume_MA'].iloc[-1])\n",
    "    return buy_signal\n",
    "\n",
    "def check_sell_signal(stock_data, short_window=5, long_window=20, rsi_sell_signal=90):\n",
    "    stock_data['Short_MA'] = calculate_moving_average(stock_data, short_window)\n",
    "    stock_data['Long_MA'] = calculate_moving_average(stock_data, long_window)\n",
    "    stock_data['RSI'] = calculate_rsi(stock_data)\n",
    "    stock_data['Volume_MA'] = stock_data['Volume'].rolling(window=short_window).mean()\n",
    "\n",
    "    # Check the latest data point for sell signal\n",
    "    sell_signal = (stock_data['Short_MA'].iloc[-1] > stock_data['Long_MA'].iloc[-1]) and \\\n",
    "                  (stock_data['RSI'].iloc[-1] > rsi_sell_signal) and \\\n",
    "                  (stock_data['Volume'].iloc[-1] > stock_data['Volume_MA'].iloc[-1])\n",
    "    return sell_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_trade(stock_data, short_window, long_window, rsi_buy_signal=40, rsi_sell_signal=90):\n",
    "    stock_data['Short_MA'] = calculate_moving_average(stock_data, short_window)\n",
    "    stock_data['Long_MA'] = calculate_moving_average(stock_data, long_window)\n",
    "    stock_data['RSI'] = calculate_rsi(stock_data)\n",
    "    stock_data['Volume_MA'] = stock_data['Volume'].rolling(window=short_window).mean()\n",
    "\n",
    "    buy_signals = (stock_data['Short_MA'] < stock_data['Long_MA']) & (stock_data['RSI'] < rsi_buy_signal) & (stock_data['Volume'] > stock_data['Volume_MA'])\n",
    "    sell_signals = (stock_data['Short_MA'] > stock_data['Long_MA']) & (stock_data['RSI'] > rsi_sell_signal) & (stock_data['Volume'] > stock_data['Volume_MA'])\n",
    "    \n",
    "    return buy_signals, sell_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended P/E Ratio for Technology: (25, 35)\n"
     ]
    }
   ],
   "source": [
    "def recommended_pe_ratio(sector):\n",
    "    pe_ratios = {\n",
    "        'Technology': (25, 35),\n",
    "        'Utilities': (10, 20),\n",
    "        'Consumer Discretionary': (15, 25),\n",
    "        'Healthcare': (15, 25),\n",
    "        'Pharmaceuticals': (15, 25),\n",
    "        'Financial': (10, 15),\n",
    "        'Energy': (5, 15),\n",
    "        'Industrials': (15, 25),\n",
    "        'Materials': (15, 25),\n",
    "        'Real Estate': (15, 25),\n",
    "        'Telecommunication': (10, 15),\n",
    "        'Consumer Staples': (20, 25),\n",
    "        'Information Technology': (25, 35)\n",
    "    }\n",
    "    \n",
    "    return pe_ratios.get(sector, ('N/A', 'N/A'))  # Default to 'N/A' if the sector is not listed\n",
    "\n",
    "# Example usage\n",
    "sector = 'Technology'\n",
    "print(f\"Recommended P/E Ratio for {sector}: {recommended_pe_ratio(sector)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(stock_data, buy_signals, sell_signals, holding_period=30, investment_fraction=0.1):\n",
    "    initial_balance = 10000  # Example starting balance\n",
    "    balance = initial_balance\n",
    "    position = 0\n",
    "    purchase_price = 0  # To track the purchase price of the stock\n",
    "    holding_start_date = None  # To track when a stock is bought\n",
    "    trade_history = []\n",
    "\n",
    "    for i in range(len(stock_data)):\n",
    "        current_date = stock_data.index[i]\n",
    "        current_price = stock_data['Close'][i]\n",
    "\n",
    "        if buy_signals[i] and balance >= current_price:\n",
    "            # Buy - use only a fraction of the available balance\n",
    "            investment_amount = balance * investment_fraction\n",
    "            shares_to_buy = investment_amount // current_price\n",
    "            if shares_to_buy > 0:  # Ensuring we have enough balance to buy at least one share\n",
    "                balance -= shares_to_buy * current_price\n",
    "                position += shares_to_buy\n",
    "                purchase_price = current_price\n",
    "                holding_start_date = current_date\n",
    "                trade_history.append(('BUY', current_date, current_price, shares_to_buy))\n",
    "\n",
    "        elif sell_signals[i] and position > 0:\n",
    "            days_held = (current_date - holding_start_date).days if holding_start_date else 0\n",
    "            is_profit = current_price > purchase_price\n",
    "\n",
    "            # Sell if held for at least 30 days or at a loss\n",
    "            if days_held >= holding_period or not is_profit:\n",
    "                balance += position * current_price\n",
    "                trade_history.append(('SELL', current_date, current_price, position))\n",
    "                position = 0\n",
    "                holding_start_date = None\n",
    "                purchase_price = 0\n",
    "\n",
    "    final_balance = balance + (position * stock_data['Close'].iloc[-1])\n",
    "    total_return = final_balance - initial_balance\n",
    "    return_percentage = (total_return / initial_balance) * 100\n",
    "\n",
    "    return trade_history, total_return, return_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define a list of stock tickers\n",
    "# # tickers = ['601288.SS', '688091.SS', '600221.SS', '600733.SS', '300169.SZ','603628.SS']\n",
    "\n",
    "# tickers = ['BTC-USD', 'ETH-USD','NVDA','AMD']\n",
    "# start_date = '2022-01-01'\n",
    "# end_date = '2024-01-19'\n",
    "\n",
    "# # Monitor each stock\n",
    "# for ticker in tickers:\n",
    "#     print(f\"Analyzing {ticker}...\")\n",
    "#     stock = get_stock_data(ticker, start_date, end_date)\n",
    "#     buy, sell = decide_trade(stock, short_window=5, long_window=20, rsi_buy_signal=30, rsi_sell_signal=90)\n",
    "\n",
    "#     # You can store these results in a data structure or database\n",
    "#     print(f\"Buy signals for {ticker}:\\n\", stock[buy])\n",
    "#     print(f\"Sell signals for {ticker}:\\n\", stock[sell])\n",
    "\n",
    "#     # Optional: Plotting\n",
    "#     plt.figure(figsize=(12,6))\n",
    "#     plt.plot(stock['Close'], label='Close Price', alpha=0.5)\n",
    "#     plt.plot(stock['Short_MA'], label='Short MA', alpha=0.9)\n",
    "#     plt.plot(stock['Long_MA'], label='Long MA', alpha=0.9)\n",
    "#     plt.scatter(stock.index[buy], stock['Close'][buy], marker='^', color='g', label='Buy Signal', alpha=1)\n",
    "#     plt.scatter(stock.index[sell], stock['Close'][sell], marker='v', color='r', label='Sell Signal', alpha=1)\n",
    "#     plt.title(f'{ticker} Stock Price with Buy & Sell Signals')\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Price')\n",
    "#     plt.legend(loc='best')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example usage\n",
    "# for ticker in tickers:\n",
    "#   stock = get_stock_data(ticker, start_date, end_date)\n",
    "#   buy, sell = decide_trade(stock, short_window=5, long_window=20, rsi_buy_signal= 30, rsi_sell_signal=90)\n",
    "#   trades, total_return, return_percentage = backtest_strategy(stock, buy, sell,30,0.1)\n",
    "#   print(f\"#######################{ticker}##########################\")\n",
    "#   print(f\"Trades: {trades}\")\n",
    "#   print(f\"Total Return: ${total_return:.2f}\")\n",
    "#   print(f\"Return Percentage: {return_percentage:.2f}%\")\n",
    "#   print(f\"Hold Return Percentage: {(stock['Close'][len(stock)-1]-stock['Close'][0])/stock['Close'][0]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_info_on_date(tickers, date=datetime.today().strftime(\"%Y-%m-%d\"), history_days=600, long_term_ma=200, rsi_buy_signal=40, rsi_sell_signal=90):\n",
    "    print(\"Today is \" + date)\n",
    "    end_date = datetime.strptime(date, '%Y-%m-%d') + timedelta(days=1)  # To include the end date in the fetch\n",
    "    start_date = end_date - timedelta(days=history_days)\n",
    "\n",
    "    market_index = yf.Ticker(\"^GSPC\")  # S&P 500 Index\n",
    "    market_data = market_index.history(start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'))\n",
    "    market_signal = get_market_exit_signal(market_data, long_term_ma)\n",
    "    print(market_signal)\n",
    "\n",
    "    data = {'Company Code': [], 'Date': [], 'Daily Price': [], 'Recommendation': [], 'P/E Ratio': [], 'Recommended PE':[], 'Category': [],'Dividend Yield': [], 'Market Cap': [], 'Earnings Growth': [], 'One Year Target': [], 'Analyst Buy': [], 'Analyst Hold': [], 'Analyst Sell': []}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist_data = stock.history(start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'))\n",
    "        if hist_data.empty:\n",
    "            continue  # Skip if no data for the given date range\n",
    "        \n",
    "        last_date = hist_data.index[-1].strftime('%Y-%m-%d')  # Last date in the historical data\n",
    "        daily_price = hist_data['Close'].iloc[-1]  # Last close price\n",
    "        # Apply buy/sell signal functions (as previously defined)\n",
    "        buy_signal = check_buy_signal(hist_data,rsi_buy_signal=rsi_buy_signal)\n",
    "        sell_signal = check_sell_signal(hist_data,rsi_sell_signal=rsi_sell_signal)\n",
    "        recommendation = 'BUY' if buy_signal else 'SELL' if sell_signal else None\n",
    "\n",
    "        if recommendation:\n",
    "            pe_ratio = stock.info.get('trailingPE', 'N/A')\n",
    "            category = stock.info.get('sector', 'N/A')\n",
    "            dividend_yield = stock.info.get('dividendYield', 'N/A') * 100 if stock.info.get('dividendYield') is not None else 'N/A'\n",
    "            market_cap = stock.info.get('marketCap', 'N/A')\n",
    "            earnings_growth = stock.info.get('earningsGrowth', 'N/A')\n",
    "            one_year_target = stock.info.get('targetMeanPrice')\n",
    "            analyst_buy_ratings = stock.info.get('buyRatingCount')\n",
    "            analyst_hold_ratings = stock.info.get('holdRatingCount')\n",
    "            analyst_sell_ratings = stock.info.get('sellRatingCount')\n",
    "            data['Company Code'].append(ticker)\n",
    "            data['Recommendation'].append(recommendation)\n",
    "            data['P/E Ratio'].append(pe_ratio)\n",
    "            data['Category'].append(category)\n",
    "            data['Dividend Yield'].append(dividend_yield)\n",
    "            data['Market Cap'].append(market_cap)\n",
    "            data['Earnings Growth'].append(earnings_growth)\n",
    "            data['Recommended PE'].append(recommended_pe_ratio(category))\n",
    "            data['One Year Target'].append(one_year_target)\n",
    "            data['Analyst Buy'].append(analyst_buy_ratings)\n",
    "            data['Analyst Hold'].append(analyst_hold_ratings)\n",
    "            data['Analyst Sell'].append(analyst_sell_ratings)\n",
    "            data['Date'].append(last_date)\n",
    "            data['Daily Price'].append(daily_price)\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp500_tickers():\n",
    "    # url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    # sp500_table = pd.read_html(url, header=0)[0]\n",
    "    # tickers = sp500_table['Symbol'].tolist()\n",
    "    # print(tickers)\n",
    "    # return tickers\n",
    "    return ['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ADBE', 'AMD', 'AES', 'AFL', 'A', 'APD', 'ABNB', 'AKAM', 'ALB', 'ARE', 'ALGN', 'ALLE', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AMCR', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'AME', 'AMGN', 'APH', 'ADI', 'ANSS', 'AON', 'APA', 'AAPL', 'AMAT', 'APTV', 'ACGL', 'ADM', 'ANET', 'AJG', 'AIZ', 'T', 'ATO', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'AXON', 'BKR', 'BALL', 'BAC', 'BK', 'BBWI', 'BAX', 'BDX', 'BRK.B', 'BBY', 'BIO', 'TECH', 'BIIB', 'BLK', 'BX', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BMY', 'AVGO', 'BR', 'BRO', 'BF.B', 'BLDR', 'BG', 'CDNS', 'CZR', 'CPT', 'CPB', 'COF', 'CAH', 'KMX', 'CCL', 'CARR', 'CTLT', 'CAT', 'CBOE', 'CBRE', 'CDW', 'CE', 'COR', 'CNC', 'CNP', 'CDAY', 'CF', 'CHRW', 'CRL', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CLX', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'COP', 'ED', 'STZ', 'CEG', 'COO', 'CPRT', 'GLW', 'CTVA', 'CSGP', 'COST', 'CTRA', 'CCI', 'CSX', 'CMI', 'CVS', 'DHR', 'DRI', 'DVA', 'DE', 'DAL', 'XRAY', 'DVN', 'DXCM', 'FANG', 'DLR', 'DFS', 'DG', 'DLTR', 'D', 'DPZ', 'DOV', 'DOW', 'DHI', 'DTE', 'DUK', 'DD', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'ELV', 'LLY', 'EMR', 'ENPH', 'ETR', 'EOG', 'EPAM', 'EQT', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'ETSY', 'EG', 'EVRG', 'ES', 'EXC', 'EXPE', 'EXPD', 'EXR', 'XOM', 'FFIV', 'FDS', 'FICO', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FSLR', 'FE', 'FI', 'FLT', 'FMC', 'F', 'FTNT', 'FTV', 'FOXA', 'FOX', 'BEN', 'FCX', 'GRMN', 'IT', 'GEHC', 'GEN', 'GNRC', 'GD', 'GE', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GL', 'GS', 'HAL', 'HIG', 'HAS', 'HCA', 'PEAK', 'HSIC', 'HSY', 'HES', 'HPE', 'HLT', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HWM', 'HPQ', 'HUBB', 'HUM', 'HBAN', 'HII', 'IBM', 'IEX', 'IDXX', 'ITW', 'ILMN', 'INCY', 'IR', 'PODD', 'INTC', 'ICE', 'IFF', 'IP', 'IPG', 'INTU', 'ISRG', 'IVZ', 'INVH', 'IQV', 'IRM', 'JBHT', 'JBL', 'JKHY', 'J', 'JNJ', 'JCI', 'JPM', 'JNPR', 'K', 'KVUE', 'KDP', 'KEY', 'KEYS', 'KMB', 'KIM', 'KMI', 'KLAC', 'KHC', 'KR', 'LHX', 'LH', 'LRCX', 'LW', 'LVS', 'LDOS', 'LEN', 'LIN', 'LYV', 'LKQ', 'LMT', 'L', 'LOW', 'LULU', 'LYB', 'MTB', 'MRO', 'MPC', 'MKTX', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MTCH', 'MKC', 'MCD', 'MCK', 'MDT', 'MRK', 'META', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MRNA', 'MHK', 'MOH', 'TAP', 'MDLZ', 'MPWR', 'MNST', 'MCO', 'MS', 'MOS', 'MSI', 'MSCI', 'NDAQ', 'NTAP', 'NFLX', 'NEM', 'NWSA', 'NWS', 'NEE', 'NKE', 'NI', 'NDSN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'NVR', 'NXPI', 'ORLY', 'OXY', 'ODFL', 'OMC', 'ON', 'OKE', 'ORCL', 'OTIS', 'PCAR', 'PKG', 'PANW', 'PARA', 'PH', 'PAYX', 'PAYC', 'PYPL', 'PNR', 'PEP', 'PFE', 'PCG', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'POOL', 'PPG', 'PPL', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PTC', 'PSA', 'PHM', 'QRVO', 'PWR', 'QCOM', 'DGX', 'RL', 'RJF', 'RTX', 'O', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RVTY', 'RHI', 'ROK', 'ROL', 'ROP', 'ROST', 'RCL', 'SPGI', 'CRM', 'SBAC', 'SLB', 'STX', 'SRE', 'NOW', 'SHW', 'SPG', 'SWKS', 'SJM', 'SNA', 'SO', 'LUV', 'SWK', 'SBUX', 'STT', 'STLD', 'STE', 'SYK', 'SYF', 'SNPS', 'SYY', 'TMUS', 'TROW', 'TTWO', 'TPR', 'TRGP', 'TGT', 'TEL', 'TDY', 'TFX', 'TER', 'TSLA', 'TXN', 'TXT', 'TMO', 'TJX', 'TSCO', 'TT', 'TDG', 'TRV', 'TRMB', 'TFC', 'TYL', 'TSN', 'USB', 'UBER', 'UDR', 'ULTA', 'UNP', 'UAL', 'UPS', 'URI', 'UNH', 'UHS', 'VLO', 'VTR', 'VLTO', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VFC', 'VTRS', 'VICI', 'V', 'VMC', 'WRB', 'WAB', 'WBA', 'WMT', 'DIS', 'WBD', 'WM', 'WAT', 'WEC', 'WFC', 'WELL', 'WST', 'WDC', 'WRK', 'WY', 'WHR', 'WMB', 'WTW', 'GWW', 'WYNN', 'XEL', 'XYL', 'YUM', 'ZBRA', 'ZBH', 'ZION', 'ZTS']\n",
    "\n",
    "sp500_tickers = get_sp500_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADBE', 'ADP', 'ABNB', 'GOOGL', 'GOOG', 'AMZN', 'AMD', 'AEP', 'AMGN', 'ADI', 'ANSS', 'AAPL', 'AMAT', 'ASML', 'AZN', 'TEAM', 'ADSK', 'BKR', 'BIIB', 'BKNG', 'AVGO', 'CDNS', 'CDW', 'CHTR', 'CTAS', 'CSCO', 'CCEP', 'CTSH', 'CMCSA', 'CEG', 'CPRT', 'CSGP', 'COST', 'CRWD', 'CSX', 'DDOG', 'DXCM', 'FANG', 'DLTR', 'DASH', 'EA', 'EXC', 'FAST', 'FTNT', 'GEHC', 'GILD', 'GFS', 'HON', 'IDXX', 'ILMN', 'INTC', 'INTU', 'ISRG', 'KDP', 'KLAC', 'KHC', 'LRCX', 'LULU', 'MAR', 'MRVL', 'MELI', 'META', 'MCHP', 'MU', 'MSFT', 'MRNA', 'MDLZ', 'MDB', 'MNST', 'NFLX', 'NVDA', 'NXPI', 'ORLY', 'ODFL', 'ON', 'PCAR', 'PANW', 'PAYX', 'PYPL', 'PDD', 'PEP', 'QCOM', 'REGN', 'ROP', 'ROST', 'SIRI', 'SPLK', 'SBUX', 'SNPS', 'TTWO', 'TMUS', 'TSLA', 'TXN', 'TTD', 'VRSK', 'VRTX', 'WBA', 'WBD', 'WDAY', 'XEL', 'ZS']\n"
     ]
    }
   ],
   "source": [
    "def get_nasdaq_tickers():\n",
    "    # url = 'https://en.wikipedia.org/wiki/NASDAQ-100'\n",
    "    # tables = pd.read_html(url)  # Scrapes all tables from the Wikipedia page\n",
    "    # nasdaq_table = tables[4]  # The table with NASDAQ tickers is typically the fourth table on the page\n",
    "    # nasdaq_tickers = nasdaq_table['Ticker'].tolist()  # Extracts the tickers into a list\n",
    "    # return nasdaq_tickers\n",
    "    return ['ADBE', 'ADP', 'ABNB', 'GOOGL', 'GOOG', 'AMZN', 'AMD', 'AEP', 'AMGN', 'ADI', 'ANSS', 'AAPL', 'AMAT', 'ASML', 'AZN', 'TEAM', 'ADSK', 'BKR', 'BIIB', 'BKNG', 'AVGO', 'CDNS', 'CDW', 'CHTR', 'CTAS', 'CSCO', 'CCEP', 'CTSH', 'CMCSA', 'CEG', 'CPRT', 'CSGP', 'COST', 'CRWD', 'CSX', 'DDOG', 'DXCM', 'FANG', 'DLTR', 'DASH', 'EA', 'EXC', 'FAST', 'FTNT', 'GEHC', 'GILD', 'GFS', 'HON', 'IDXX', 'ILMN', 'INTC', 'INTU', 'ISRG', 'KDP', 'KLAC', 'KHC', 'LRCX', 'LULU', 'MAR', 'MRVL', 'MELI', 'META', 'MCHP', 'MU', 'MSFT', 'MRNA', 'MDLZ', 'MDB', 'MNST', 'NFLX', 'NVDA', 'NXPI', 'ORLY', 'ODFL', 'ON', 'PCAR', 'PANW', 'PAYX', 'PYPL', 'PDD', 'PEP', 'QCOM', 'REGN', 'ROP', 'ROST', 'SIRI', 'SPLK', 'SBUX', 'SNPS', 'TTWO', 'TMUS', 'TSLA', 'TXN', 'TTD', 'VRSK', 'VRTX', 'WBA', 'WBD', 'WDAY', 'XEL', 'ZS']\n",
    "\n",
    "nasdaq_tickers = get_nasdaq_tickers()\n",
    "print(nasdaq_tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useless Stock Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rules\n",
    "# def rule_price_above_moving_averages(stock_data):\n",
    "#     \"\"\"Price and 50-day MA higher than both 150-day and 200-day MAs.\"\"\"\n",
    "#     ma50 = stock_data['Close'].rolling(window=50).mean()\n",
    "#     ma150 = stock_data['Close'].rolling(window=150).mean()\n",
    "#     ma200 = stock_data['Close'].rolling(window=200).mean()\n",
    "#     current_price = stock_data['Close'].iloc[-1]\n",
    "#     # print(current_price)\n",
    "#     # print(ma50.iloc[-1])\n",
    "#     # print(ma150.iloc[-1])\n",
    "#     # print(ma200.iloc[-1])\n",
    "#     # print(current_price > ma150.iloc[-1] and current_price > ma200.iloc[-1] and ma50.iloc[-1] > ma150.iloc[-1] and ma50.iloc[-1] > ma200.iloc[-1])\n",
    "#     return current_price > ma150.iloc[-1] and current_price > ma200.iloc[-1] and ma50.iloc[-1] > ma150.iloc[-1] and ma50.iloc[-1] > ma200.iloc[-1]\n",
    "\n",
    "# def rule_ma200_uptrend(stock_data, days=30):\n",
    "#     \"\"\"200-day MA has been in an uptrend for at least 'days' days.\"\"\"\n",
    "#     ma200 = stock_data['Close'].rolling(window=200).mean()\n",
    "#     # for every ten days, check if it is still the trend\n",
    "#     for i in range(-1, -days, -10):\n",
    "#         # print(ma200.iloc[-10*i-1],ma200.iloc[-10*i+9])\n",
    "#         if ma200.iloc[-10*i-1] >= ma200.iloc[-10*i+9]:\n",
    "#             return False\n",
    "#     # print(ma200.iloc[-1] > ma200.iloc[-days])\n",
    "#     return True \n",
    "#     # return ma200.iloc[-1] > ma200.iloc[-days]\n",
    "\n",
    "# def rule_price_above_52week_low(stock_data, threshold=0.25):\n",
    "#     \"\"\"Current price is at least 'threshold' % higher than the 52-week low.\"\"\"\n",
    "#     low_52week = stock_data['Close'].rolling(window=252).min().iloc[-1]\n",
    "#     current_price = stock_data['Close'].iloc[-1]\n",
    "#     # print(current_price >= low_52week * (1 + threshold))\n",
    "#     return current_price >= low_52week * (1 + threshold)\n",
    "\n",
    "# def rule_price_near_52week_high(stock_data, threshold=0.25):\n",
    "#     \"\"\"Current price is within 'threshold' % of the 52-week high.\"\"\"\n",
    "#     high_52week = stock_data['Close'].rolling(window=252).max().iloc[-1]\n",
    "#     current_price = stock_data['Close'].iloc[-1]\n",
    "#     # print(current_price >= high_52week * (1 - threshold))\n",
    "#     return current_price >= high_52week * (1 - threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_filter(tickers, rules,date = datetime.today().strftime(\"%Y-%m-%d\")):\n",
    "#     filtered_stocks = []\n",
    "#     for ticker in tickers:\n",
    "#         end_date = datetime.strptime(date, '%Y-%m-%d') + timedelta(days=1)  # To include the end date in the fetch\n",
    "#         min_history_days = 3*365\n",
    "#         start_date = end_date - timedelta(days=min_history_days)\n",
    "#         try:\n",
    "#             data = yf.download(ticker, start=start_date, end=date, progress=False)\n",
    "#             if all(rule(data) for rule in rules):\n",
    "#                 filtered_stocks.append(ticker)\n",
    "#             # else:\n",
    "#                 # print(ticker + ' is not recommended to trade')\n",
    "#         except:\n",
    "#             continue\n",
    "#     return filtered_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_rules = [\n",
    "#     rule_price_above_moving_averages,\n",
    "#     rule_ma200_uptrend,\n",
    "#     rule_price_above_52week_low,\n",
    "#     rule_price_near_52week_high\n",
    "# ]\n",
    "\n",
    "# # List of tickers\n",
    "# # tickers = ['AAPL','AMD','ARKK','ARM','BA', 'BABA','BAC','BILI','BNTX', 'COF', 'COIN', 'COST', 'CRM', 'DASH', 'DDOG', 'DIS', 'GOOGL', 'HOOD', 'ISRG', 'JPM', 'KO', 'KRE', 'LYFT', 'MDB','META', 'MSFT', 'NKE', 'NVDA', 'ORCL', 'OXY', 'PDD', 'PLTR', 'RBLX', 'SAVE', 'SHOP', 'SNOW', 'SOFI', 'TMF', 'TSLA', 'TSM', 'UAL', 'UBER','UHAL', 'WFC','XOM']\n",
    "# tickers = nasdaq_tickers\n",
    "# tickers.append(sp500_tickers)\n",
    "# # tickers=['AAPL',\"NVDA\",\"TSLA\",\"MSFT\",\"COIN\"]\n",
    "# # tickers = ['NVDA']\n",
    "# # Apply the filter\n",
    "# filtered_stocks = stock_filter(tickers, filter_rules)\n",
    "# print(\"Stocks that meet the criteria:\", filtered_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_stock_filter_performance(tickers, rules, start_date, end_date):\n",
    "#     passed_stocks = stock_filter(tickers, rules, start_date)\n",
    "#     failed_stocks = set(tickers) - set(passed_stocks)\n",
    "\n",
    "#     return calculate_average_return(passed_stocks, start_date, end_date), calculate_average_return(failed_stocks, start_date, end_date), passed_stocks, failed_stocks\n",
    "\n",
    "# def calculate_average_return(stocks, start_date, end_date):\n",
    "#     returns = []\n",
    "#     annualized_returns = []\n",
    "#     start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "#     end = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "#     days_in_period = (end - start).days\n",
    "#     for ticker in stocks:\n",
    "#         try:\n",
    "#             stock_data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "            \n",
    "#             if not stock_data.empty:\n",
    "#                 initial_price = stock_data['Close'].iloc[0]\n",
    "#                 final_price = stock_data['Close'].iloc[-1]\n",
    "#                 stock_return = (final_price - initial_price) / initial_price\n",
    "#                 annualized_return = (1 + stock_return) ** (365.0 / days_in_period) - 1\n",
    "#                 returns.append(stock_return)\n",
    "#                 annualized_returns.append(annualized_return)\n",
    "#         except:\n",
    "#             continue\n",
    "#     if returns:\n",
    "#         return sum(returns) / len(returns), sum(annualized_returns)/len(annualized_returns)\n",
    "#     else:\n",
    "#         # need a better solution\n",
    "#         return 0, 0\n",
    "\n",
    "# # Example usage\n",
    "# tickers = sp500_tickers\n",
    "# start_date = \"2023-01-01\"\n",
    "# end_date = '2023-12-01'\n",
    "\n",
    "# average_return_passed, average_return_failed, passed_stocks, failed_stocks = test_stock_filter_performance(tickers, filter_rules, start_date, end_date)\n",
    "# print(\"Average yearly Return of Passed Stocks:\", average_return_passed[1], \"Number of Passed Stocks: \", len(passed_stocks))\n",
    "# print(passed_stocks)\n",
    "# print(\"Average yearly Return of Failed Stocks:\", average_return_failed[1], \"Number of Failed Stocks: \", len(failed_stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def closest_trading_date(data, date):\n",
    "#     \"\"\"Find the closest previous trading date in the data for a given date.\"\"\"\n",
    "#     if date in data.index:\n",
    "#         return date\n",
    "#     # Iterate backwards to find the closest previous date\n",
    "#     while date not in data.index:\n",
    "#         date -= pd.Timedelta(days=1)\n",
    "#     return date\n",
    "\n",
    "# def test_filter_performance_over_periods(tickers, rules, start_date, end_date):\n",
    "  \n",
    "#     # Generate dates at regular intervals between start and end\n",
    "#     date_range = pd.date_range(start=start_date, end=end_date, freq='M')\n",
    "#     filtered_stocks = stock_filter(tickers, rules, start_date)\n",
    "#     unfiltered_stocks = set(tickers) - set(filtered_stocks)\n",
    "\n",
    "#     # Lists to store results\n",
    "#     filtered_returns = []\n",
    "#     unfiltered_returns = []\n",
    "#     differences = []\n",
    "#     sp500_returns = []\n",
    "\n",
    "#     sp500 = yf.download('^GSPC', start=start_date, end=end_date, progress=False)['Close']\n",
    "    \n",
    "#     for date in date_range:\n",
    "#         trading_date = closest_trading_date(sp500, date)\n",
    "\n",
    "#         filtered_avg_return, _ = calculate_average_return(filtered_stocks, start_date, date.strftime('%Y-%m-%d'))\n",
    "#         unfiltered_avg_return, _ = calculate_average_return(unfiltered_stocks, start_date, date.strftime('%Y-%m-%d'))\n",
    "\n",
    "#         sp500_return = (sp500.loc[trading_date] - sp500[0]) / sp500[0]\n",
    "\n",
    "#         filtered_returns.append(filtered_avg_return if filtered_avg_return is not None else 0)\n",
    "#         unfiltered_returns.append(unfiltered_avg_return if unfiltered_avg_return is not None else 0)\n",
    "#         differences.append((filtered_avg_return - unfiltered_avg_return) if filtered_avg_return is not None and unfiltered_avg_return is not None else 0)\n",
    "#         sp500_returns.append(sp500_return)\n",
    "\n",
    "#     return date_range, filtered_returns, unfiltered_returns, differences, sp500_returns\n",
    "\n",
    "\n",
    "# start_date = '2022-05-01'\n",
    "# end_date = '2024-01-01'\n",
    "# tickers = nasdaq_tickers[30:70]\n",
    "# date_range, filtered_returns, unfiltered_returns, differences, sp500_returns = test_filter_performance_over_periods(tickers, filter_rules, start_date, end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(date_range, filtered_returns, label='Filtered Stocks')\n",
    "# plt.plot(date_range, unfiltered_returns, label='Unfiltered Stocks')\n",
    "# plt.plot(date_range, differences, label='Difference (Filtered - Unfiltered)')\n",
    "# plt.plot(date_range, sp500_returns, label='S&P 500', linestyle='--')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Average Return')\n",
    "# plt.title('Performance Comparison Over Time')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_price_increase(stock_data):\n",
    "    \"\"\"Rule 2: 25-50% increase in 1 to 3 weeks.\"\"\"\n",
    "    period_returns = stock_data['Close'].pct_change(periods=5).iloc[-1]  # 1-week return\n",
    "    return 0.25 <= period_returns <= 0.50\n",
    "\n",
    "def rule_largest_gain(stock_data):\n",
    "    \"\"\"Rule 3: Largest single-day gain since rise began.\"\"\"\n",
    "    daily_gains = stock_data['Close'].pct_change()\n",
    "    max_gain = daily_gains.max()\n",
    "    recent_gain = daily_gains.iloc[-1]\n",
    "    return recent_gain == max_gain\n",
    "\n",
    "def rule_accelerating_growth(stock_data):\n",
    "    \"\"\"Rule 6: 6-10 days of accelerating growth, with only about 2 days of decline.\"\"\"\n",
    "    recent_data = stock_data['Close'].iloc[-10:]\n",
    "    up_days = recent_data.pct_change() > 0\n",
    "    return up_days.sum() >= 8\n",
    "\n",
    "def rule_falling_below_ma(stock_data):\n",
    "    \"\"\"Rule 10: Falling below 50-day MA on largest volume.\"\"\"\n",
    "    ma50 = stock_data['Close'].rolling(window=50).mean().iloc[-1]\n",
    "    max_volume = stock_data['Volume'].max()\n",
    "    recent_volume = stock_data['Volume'].iloc[-1]\n",
    "    current_price = stock_data['Close'].iloc[-1]\n",
    "    return current_price < ma50 and recent_volume == max_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_warning_system(tickers, date, rules):\n",
    "    warnings = {}\n",
    "    end_date = datetime.strptime(date, '%Y-%m-%d') + timedelta(days=1)  # To include the end date in the fetch\n",
    "    start_date = end_date - timedelta(days=365)\n",
    "    for ticker in tickers:\n",
    "        data = yf.download(ticker, start=start_date, end=date)\n",
    "        for rule in rules:\n",
    "            if rule(data):\n",
    "                warnings.setdefault(ticker, []).append(rule.__name__)\n",
    "    return warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define your rules\n",
    "# warning_rules = [rule_price_increase, rule_largest_gain, rule_accelerating_growth, rule_falling_below_ma]  # Add other rule functions here\n",
    "\n",
    "# # List of tickers and a specific date\n",
    "# # tickers = ['AAPL', 'MSFT', 'GOOG']\n",
    "# tickers = nasdaq_tickers\n",
    "# date = '2024-01-03'  # Replace with your date\n",
    "\n",
    "# # Get warnings \n",
    "# warnings = stock_warning_system(tickers, date, warning_rules)\n",
    "# print(\"Warnings:\", warnings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upcoming_earnings(tickers, reference_date, within_days=10):\n",
    "    reference_date = datetime.strptime(reference_date, '%Y-%m-%d')\n",
    "    days_later = reference_date + timedelta(days=within_days)\n",
    "    earnings_list = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        try:\n",
    "            info = stock.info\n",
    "            if 'earningsQuarterlyGrowth' not in info: # filter out etfs\n",
    "                continue\n",
    "            earnings_data = stock.calendar\n",
    "            if earnings_data and 'Earnings Date' in earnings_data:\n",
    "                if len(earnings_data['Earnings Date']) > 0:\n",
    "                    earnings_date = earnings_data['Earnings Date'][0]\n",
    "                    earnings_date = pd.to_datetime(earnings_date).to_pydatetime()\n",
    "                    if reference_date <= earnings_date < days_later:\n",
    "                        earnings_list.append((ticker, earnings_date))\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "    # Sort the list by earnings date\n",
    "    earnings_list.sort(key=lambda x: x[1])\n",
    "    return earnings_list\n",
    "\n",
    "# Example usage\n",
    "# tickers = ['AAPL', 'MSFT', 'GOOG', 'AMZN']  # Replace with your list of tickers\n",
    "# date = '2024-01-24'  # Replace with your reference date\n",
    "\n",
    "# stocks_with_upcoming_earnings = upcoming_earnings(tickers, date)\n",
    "# for ticker, earnings_date in stocks_with_upcoming_earnings:\n",
    "#     print(f\"{ticker}: Earnings on {earnings_date}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candlestick Pattern detection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_bullish_engulfing(data):\n",
    "#     # Check if the last two days form a bullish engulfing pattern\n",
    "#     if len(data) >= 2:\n",
    "#         last_day = data.iloc[-1]\n",
    "#         prev_day = data.iloc[-2]\n",
    "#         # print(last_day['Open'], last_day['Close'])\n",
    "#         return (last_day['Open'] < last_day['Close'] and  # Last day is bullish\n",
    "#                 prev_day['Open'] > prev_day['Close'] and  # Previous day is bearish\n",
    "#                 last_day['Open'] < prev_day['Close'] and  # Last day's open is lower than prev day's close\n",
    "#                 last_day['Close'] > prev_day['Open'])     # Last day's close is higher than prev day's open\n",
    "#     return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def candlestick_alerts(tickers, patterns, date):\n",
    "#     alerts = {}\n",
    "#     end_date = pd.to_datetime(date)+pd.Timedelta(days=1)\n",
    "#     start_date = end_date - pd.Timedelta(days=30)  # Assuming 30 days is enough to detect patterns\n",
    "\n",
    "#     for ticker in tickers:\n",
    "#         data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        \n",
    "#         for pattern in patterns:\n",
    "#             if pattern(data):\n",
    "#                 alerts.setdefault(ticker, []).append(pattern.__name__)\n",
    "\n",
    "#     return alerts\n",
    "\n",
    "# # Example usage\n",
    "# tickers = ['NVDA']\n",
    "# patterns = [is_bullish_engulfing]  # Add more patterns as needed\n",
    "# date = '2023-08-14'\n",
    "\n",
    "# alerts = candlestick_alerts(tickers, patterns, date)\n",
    "# print(alerts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everyday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'AAL', 'ASML', 'AMD', 'ABNB', 'ALK', 'ARKK', 'ARM', 'ANET', 'BABA', 'BAC', 'BILI', 'BNTX', 'C', 'CDNS', 'CVNA', 'COF', 'COIN', 'COST', 'CRM', 'DASH', 'DAL', 'DDOG', 'DIS', 'GOOGL', 'HOOD', 'ISRG', 'JPM', 'KO', 'KRE', 'LYFT', 'LLY', 'MDB', 'META', 'MSFT', 'NKE', 'NEE', 'NVDA', 'NVO', 'ORCL', 'OXY', 'PDD', 'PLTR', 'PFE', 'RBLX', 'SAVE', 'SHOP', 'SNOW', 'SOFI', 'SMCI', 'SNAP', 'SBUX', 'SPOT', 'INTC', 'BA', 'TMF', 'TRV', 'TSLA', 'TSM', 'UAL', 'UBER', 'UHAL', 'UPS', 'WFC', 'XOM', 'DHI', 'MMM', 'NFLX', '601288.SS', '688091.SS', '600221.SS', '600733.SS', '300169.SZ', '603628.SS', 'BTC-USD', 'ETH-USD']\n",
      "Today is 2024-02-16\n",
      "Stay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warnings: {'LYFT': ['rule_price_increase'], 'OXY': ['rule_largest_gain'], 'SMCI': ['rule_price_increase', 'rule_accelerating_growth'], 'WFC': ['rule_largest_gain'], 'BTC-USD': ['rule_accelerating_growth']}\n",
      "NVDA: Earnings on 2024-02-21 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Daily Price</th>\n",
       "      <th>Recommendation</th>\n",
       "      <th>P/E Ratio</th>\n",
       "      <th>Recommended PE</th>\n",
       "      <th>Category</th>\n",
       "      <th>Dividend Yield</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Earnings Growth</th>\n",
       "      <th>One Year Target</th>\n",
       "      <th>Analyst Buy</th>\n",
       "      <th>Analyst Hold</th>\n",
       "      <th>Analyst Sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LLY</td>\n",
       "      <td>2024-02-16</td>\n",
       "      <td>782.059998</td>\n",
       "      <td>SELL</td>\n",
       "      <td>141.42133</td>\n",
       "      <td>(15, 25)</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>0.69</td>\n",
       "      <td>742415007744</td>\n",
       "      <td>0.131</td>\n",
       "      <td>754.33</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company Code        Date  Daily Price Recommendation  P/E Ratio  \\\n",
       "0          LLY  2024-02-16   782.059998           SELL  141.42133   \n",
       "\n",
       "  Recommended PE    Category  Dividend Yield    Market Cap  Earnings Growth  \\\n",
       "0       (15, 25)  Healthcare            0.69  742415007744            0.131   \n",
       "\n",
       "   One Year Target Analyst Buy Analyst Hold Analyst Sell  \n",
       "0           754.33        None         None         None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "# tickers = get_nasdaq_tickers() # List of tickers\n",
    "# tickers = get_sp500_tickers()\n",
    "date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "# date = '2024-01-06'\n",
    "crypto = ['BTC-USD', 'ETH-USD']\n",
    "cn_tickers = ['601288.SS', '688091.SS', '600221.SS', '600733.SS', '300169.SZ','603628.SS']\n",
    "tickers = ['AAPL','AAL', 'ASML','AMD', 'ABNB','ALK', 'ARKK','ARM', 'ANET','BABA','BAC','BILI','BNTX','C', 'CDNS', 'CVNA','COF', 'COIN', 'COST', 'CRM', 'DASH', 'DAL', 'DDOG', 'DIS', 'GOOGL', 'HOOD', 'ISRG', 'JPM', 'KO', 'KRE', 'LYFT', 'LLY', 'MDB','META', 'MSFT', 'NKE','NEE', 'NVDA', 'NVO', 'ORCL', 'OXY', 'PDD', 'PLTR', 'PFE', 'RBLX', 'SAVE', 'SHOP', 'SNOW', 'SOFI', 'SMCI', 'SNAP', 'SBUX', 'SPOT','INTC', 'BA', 'TMF', 'TRV', 'TSLA', 'TSM', 'UAL', 'UBER','UHAL', 'UPS', 'WFC','XOM', 'DHI', 'MMM', 'NFLX']\n",
    "tickers = tickers + cn_tickers + crypto\n",
    "# tickers = sp500_tickers + nasdaq_tickers\n",
    "print(tickers)\n",
    "stock_table = get_stock_info_on_date(tickers, date,rsi_buy_signal=20,rsi_sell_signal=90)\n",
    "\n",
    "\n",
    "warning_rules = [rule_price_increase, rule_largest_gain, rule_accelerating_growth, rule_falling_below_ma]\n",
    "warnings = stock_warning_system(tickers, date, warning_rules)\n",
    "print(\"Warnings:\", warnings)\n",
    "\n",
    "stocks_with_upcoming_earnings = upcoming_earnings(tickers, date)\n",
    "for ticker, earnings_date in stocks_with_upcoming_earnings:\n",
    "    print(f\"{ticker}: Earnings on {earnings_date}\")\n",
    "\n",
    "# Set the display.max_rows option to None\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(stock_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats415",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
